{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fac01e8",
   "metadata": {},
   "source": [
    "# 1. HDB Resale Data Collection\n",
    "\n",
    "Import dataset from excel/csv file. Data can be found in https://data.gov.sg/dataset/resale-flat-prices (if using csv/excel import, have to consolidate into a combined file). API method as per below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760e94fe",
   "metadata": {},
   "source": [
    "#### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea3fc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#libraries\n",
    "import urllib\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "pd.set_option('display.max_rows', 500)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bcb3db",
   "metadata": {},
   "source": [
    "#### Calling data.gov.sg data for HDB data\n",
    "\n",
    "- Importing them as JSON and converting them into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249b3bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# #Year 1990 to 1999 (287196 records, 10 columns)\n",
    "# url_1990 = 'https://data.gov.sg/api/action/datastore_search?resource_id=adbbddd3-30e2-445f-a123-29bee150a6fe&limit=1000000'\n",
    "# data_1990 = requests.get(url_1990).json()\n",
    "# df_1990 = pd.DataFrame.from_dict(data_1990['result']['records'])\n",
    "\n",
    "# #Year 2000 to Feb 2012 (369651 records, 10 columns)\n",
    "# url_2000 = 'https://data.gov.sg/api/action/datastore_search?resource_id=8c00bf08-9124-479e-aeca-7cc411d884c4&limit=1000000'\n",
    "# data_2000 = requests.get(url_2000).json()\n",
    "# df_2000 = pd.DataFrame.from_dict(data_2000['result']['records'])\n",
    "\n",
    "# #Year Mar 2012 to Dec 2014 (52203 records, 10 columns)\n",
    "# url_2012 = 'https://data.gov.sg/api/action/datastore_search?resource_id=83b2fc37-ce8c-4df4-968b-370fd818138b&limit=1000000'\n",
    "# data_2012 = requests.get(url_2012).json()\n",
    "# df_2012 = pd.DataFrame.from_dict(data_2012['result']['records'])\n",
    "\n",
    "# #Year Mar 2015 to Dec 2016 (37153 records, 11 columns)\n",
    "# url_2015 = 'https://data.gov.sg/api/action/datastore_search?resource_id=1b702208-44bf-4829-b620-4615ee19b57c&limit=1000000'\n",
    "# data_2015 = requests.get(url_2015).json()\n",
    "# df_2015 = pd.DataFrame.from_dict(data_2015['result']['records'])\n",
    "\n",
    "#Year Jan 2017 to recent (238060 records, 11 columns)\n",
    "url_2017 = 'https://data.gov.sg/api/action/datastore_search?resource_id=f1765b54-a209-4718-8d38-a39237f502b3&limit=1000000'\n",
    "data_2017 = requests.get(url_2017).json()\n",
    "df_2017 = pd.DataFrame.from_dict(data_2017['result']['records'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b8b2b",
   "metadata": {},
   "source": [
    "#### Add 'remaining_lease' column to dataset that is missing. And append all 5 datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2ba9d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 647 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# #1990 -- > re-arranging and adding remaining lease \n",
    "# df_1990['remaining_lease_on_sale'] = (df_1990['lease_commence_date'].astype(int) + 99) - (pd.to_datetime(df_1990['month']).dt.year)\n",
    "# df_1990 = df_1990[['_id', 'month', 'town', 'flat_type', 'block', 'street_name', 'storey_range', 'floor_area_sqm', 'flat_model', 'lease_commence_date', 'remaining_lease_on_sale','resale_price']]\n",
    "\n",
    "# #2000 -- > re-arranging and adding remaining lease \n",
    "# df_2000['remaining_lease_on_sale'] = (df_2000['lease_commence_date'].astype(int) + 99) - (pd.to_datetime(df_2000['month']).dt.year)\n",
    "# df_2000 = df_2000[['_id', 'month', 'town', 'flat_type', 'block', 'street_name', 'storey_range', 'floor_area_sqm', 'flat_model', 'lease_commence_date', 'remaining_lease_on_sale','resale_price']]\n",
    "\n",
    "# #2012 -- > re-arranging columns and adding remaining lease\n",
    "# df_2012['remaining_lease_on_sale'] = (df_2012['lease_commence_date'].astype(int) + 99) - (pd.to_datetime(df_2012['month']).dt.year)\n",
    "# df_2012 = df_2012[['_id', 'month', 'town', 'flat_type', 'block', 'street_name', 'storey_range', 'floor_area_sqm', 'flat_model', 'lease_commence_date', 'remaining_lease_on_sale','resale_price']]\n",
    "\n",
    "# #2015 -- > re-arranging columns \n",
    "# df_2015 = df_2015.rename(columns={'remaining_lease': 'remaining_lease_on_sale'})\n",
    "# df_2015 = df_2015[['_id', 'month', 'town', 'flat_type', 'block', 'street_name', 'storey_range', 'floor_area_sqm', 'flat_model', 'lease_commence_date', 'remaining_lease_on_sale','resale_price']]\n",
    "\n",
    "#2017 -- > re-arranging columns and aggregating remaining_lease column\n",
    "df_2017['remaining_lease_on_sale'] = (df_2017['lease_commence_date'].astype(int) + 99) - (pd.to_datetime(df_2017['month']).dt.year)\n",
    "df_2017['floor_area_sqft'] = df_2017['floor_area_sqm'].astype(float) * 10.76391042\n",
    "df_2017['floor_area_sqft'] = df_2017['floor_area_sqft'].round(0)\n",
    "df_2017 = df_2017[['_id', 'month', 'town', 'flat_type', 'block', 'street_name', 'storey_range', 'floor_area_sqm', 'floor_area_sqft', 'flat_model', 'lease_commence_date', 'remaining_lease_on_sale', 'resale_price']]\n",
    "#df_2017 = df_2017.drop('remaining_lease', axis = 1)\n",
    "\n",
    "df_hdb_consolidated = df_2017.copy()\n",
    "df_hdb_consolidated = df_hdb_consolidated.drop('_id', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de901d",
   "metadata": {},
   "source": [
    "# 2. Map data collection\n",
    "\n",
    "#### Getting the coordinates from OneMap API, \n",
    "\n",
    "- Time taken to reach the nearest Hawker Centre\n",
    "- Time taken to reach Raffles Place MRT Station\n",
    "- Time taken to reach the nearest mall\n",
    "- Time taken to reach the nearest MRT Station\n",
    "- Top 30 Schools (within 2km distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb36c0",
   "metadata": {},
   "source": [
    "#### Get Postal, X Coordinate, Y Coordinate, Longitude, Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b541d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "<timed exec>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_hdb_consolidated['street_name'] = df_hdb_consolidated['street_name'].str.replace(\"ST. GEORGE'S RD\", \"ST GEORGE'S RD\") # data cleansing for API request\n",
    "df_hdb_consolidated['street_name'] = df_hdb_consolidated['street_name'].str.replace(\"ST. GEORGE'S LANE\", \"ST GEORGE'S LANE\") # data cleansing for API request\n",
    "\n",
    "df_hdb_consolidated['address'] = df_hdb_consolidated['block'].astype(str) + \" \" + df_hdb_consolidated['street_name'].astype(str)\n",
    "df_hdb_consolidated = df_hdb_consolidated[['month', 'town', 'flat_type', 'block', 'street_name', 'address', 'storey_range', 'floor_area_sqm', 'floor_area_sqft', 'flat_model', 'lease_commence_date', 'remaining_lease_on_sale', 'resale_price']]\n",
    "\n",
    "df_hdb_consolidated.to_excel(r'output\\1. HDB data (DataFrame).xlsx')\n",
    "\n",
    "### to create for the lat and long, one time (to comment out) ###\n",
    "# df_location_coordinates = pd.DataFrame(df_hdb_consolidated['address'].unique(), columns=['address'])\n",
    "# url_lat_long = 'https://developers.onemap.sg/commonapi/search?returnGeom=Y&getAddrDetails=Y&searchVal='\n",
    "# counter = 0\n",
    "\n",
    "def get_LatLong(): #define as a method so that we wont keep running this\n",
    "    global df_location_coordinates\n",
    "    global counter\n",
    "\n",
    "    for index in df_location_coordinates.iloc[counter:].iterrows():\n",
    "        try: \n",
    "            print('Finished ' + str(counter))\n",
    "            request_lat_long = url_lat_long + (index[1][0])\n",
    "            response_lat_long = requests.get(request_lat_long).json()\n",
    "            df_location_coordinates.loc[counter,'postal'] = pd.json_normalize(response_lat_long['results'])['POSTAL'][0] # another JSON to dataframe method\n",
    "            df_location_coordinates.loc[counter,'x_coord'] = pd.json_normalize(response_lat_long['results'])['X'][0]\n",
    "            df_location_coordinates.loc[counter,'y_coord'] = pd.json_normalize(response_lat_long['results'])['Y'][0]\n",
    "            df_location_coordinates.loc[counter,'latitude'] = pd.json_normalize(response_lat_long['results'])['LATITUDE'][0]\n",
    "            df_location_coordinates.loc[counter,'longitude'] = pd.json_normalize(response_lat_long['results'])['LONGITUDE'][0]\n",
    "            counter+=1\n",
    "        except KeyError:\n",
    "            print('Error occurred at: ' + str(counter))\n",
    "            counter+=1\n",
    "\n",
    "#get_LatLong()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b34eb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location_coordinates = pd.read_excel(r'output\\2. address_lat_long_coordinates.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d65c82",
   "metadata": {},
   "source": [
    "#### Hawker Centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "infile = open(str(\"data/Hawker/hawker-centres-kml.kml\"),\"r\")\n",
    "contents  = infile.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f040c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hdb_consolidated.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564341e",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing / Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677bb25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86816ce2",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6490a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
